{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f626d-4306-4a8d-93e0-333a830a5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cbbd8-06ab-4e89-abf0-583f654b1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8944ef-41e5-454e-8ff9-13694b089b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d9796-bb45-4628-8ab6-99533b61f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "from gprofiler import gprofiler\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import drvi\n",
    "from drvi.model import DRVI\n",
    "from drvi.utils.misc import hvg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58680210-ccfa-433a-8129-57a6208429b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=100, frameon=False)\n",
    "sc.set_figure_params(dpi=100)\n",
    "sc.set_figure_params(figsize=(3, 3))\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9dead1-1bdd-4073-8a1c-0e0c3086951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"/work/DRVI/fixed_data/HTAPP/HTAPP_997_processed_raw_FINAL.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6e4f9-1b0a-4059-a90b-f8aa298c3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11e0f8-aa4f-489c-8366-02ec58cdc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers[\"counts\"] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d7dd9-56d2-4f94-884c-157689815760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "split_key = \"split\"\n",
    "adata.obs[split_key] = \"train\"\n",
    "idx = list(range(len(adata)))\n",
    "idx_train, idx_test = train_test_split(adata.obs_names, test_size=0.1, random_state=42)\n",
    "adata.obs.loc[idx_train, split_key] = \"train\"\n",
    "adata.obs.loc[idx_test, split_key] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398385d-cd38-4ca3-9d81-4181f60f4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adata = adata[adata.obs[split_key] == \"train\"].copy()\n",
    "test_adata = adata[adata.obs[split_key] == \"test\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36151d85-d09c-4b09-9b44-edd7246bda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data\n",
    "DRVI.setup_anndata(\n",
    "    train_adata,\n",
    "    # DRVI accepts count data by default.\n",
    "    # Do not forget to change gene_likelihood if you provide a non-count data.\n",
    "    layer=\"counts\",\n",
    "    # Always provide a list. DRVI can accept multiple covariates.\n",
    "    categorical_covariate_keys=[\"replicate\"],\n",
    "    # DRVI accepts count data by default.\n",
    "    # Set to false if you provide log-normalized data and use normal distribution (mse loss).\n",
    "    is_count_data=True,\n",
    ")\n",
    "\n",
    "# construct the model\n",
    "model = DRVI(\n",
    "    train_adata,\n",
    "    # Provide categorical covariates keys once again. Refer to advanced usages for more options.\n",
    "    categorical_covariates=[\"replicate\"],\n",
    "    n_latent=128,\n",
    "    # For encoder and decoder dims, provide a list of integers.\n",
    "    encoder_dims=[128, 128],\n",
    "    decoder_dims=[128, 128],\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292e4e1-14f6-44f7-a65d-81454427ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cpu training you should add the following line to the model.train parameters:\n",
    "#accelerator=\"cpu\", devices=1,\n",
    "#\n",
    "# For mps acceleration on macbooks, add the following line to the model.train parameters:\n",
    "# accelerator=\"mps\", devices=1,\n",
    "#\n",
    "# For gpu training don't provide any additional parameter.\n",
    "# More details here: https://lightning.ai/docs/pytorch/stable/accelerators/gpu_basic.html\n",
    "\n",
    "n_epochs = 400\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    max_epochs=n_epochs,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=20,\n",
    "    # mps\n",
    "    # accelerator=\"mps\", devices=1,\n",
    "    # cpu\n",
    "    #accelerator=\"cpu\", devices=1,\n",
    "    # gpu: no additional parameter\n",
    "    #\n",
    "    # No need to provide `plan_kwargs` if n_epochs >= 400.\n",
    "    plan_kwargs={\n",
    "        \"n_epochs_kl_warmup\": n_epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Runtime:\n",
    "# The runtime for CPU laptop (M1) is 208 minutes\n",
    "# The runtime for Macbook gpu (M1) is 64 minutes\n",
    "# The runtime for GPU (A100) is 17 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ada33-0b2f-4645-81de-e3f04e8ef61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"FIXED_trained_models/DRVI_HTAPP_train_batch_removal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7558b-9c3a-4b39-87ef-d49a39db28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(\"/work/DRVI/trained_models/DRVI_HTAPP_train_3/\", adata = train_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4aeb98-5996-4f0a-a915-aa7e78feab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1b02d-8c2c-4d33-b378-426210e0bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out\n",
    "test_adata = test_adata[test_adata.obs[\"cell_type\"] != \"mature NK T cell\"].copy()\n",
    "adata = test_adata[test_adata.obs[\"cell_type\"] != \"mature NK T cell\"].copy()\n",
    "\n",
    "def predict(model, adata):\n",
    "    model._validate_anndata(adata)\n",
    "    model.module.eval()\n",
    "\n",
    "    scdl = model._make_data_loader(adata=adata, indices=None, batch_size=128, shuffle=False)\n",
    "    mus = []\n",
    "    for tensors in scdl:\n",
    "        inference_outputs, generative_outputs = model.module.forward(\n",
    "                    tensors,\n",
    "                    compute_loss=False,\n",
    "                )\n",
    "        _mus = torch.nan_to_num(generative_outputs['px'].mean, nan=0, neginf=0, posinf=100) \n",
    "        mus.append(_mus.detach().cpu().numpy())\n",
    "    mus = np.concatenate(mus, axis=0)\n",
    "    out_adata = adata.copy()\n",
    "    out_adata.X = mus\n",
    "    return out_adata\n",
    "\n",
    "\n",
    "model._validate_anndata(test_adata)\n",
    "rec = predict(model, test_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd4388-c22a-45c3-bc25-17203ff7cb95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = model.get_latent_representation(\n",
    "    adata,\n",
    "    batch_size=256,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd72d99-23a6-4f8f-8f7f-27a464f72e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If rec is an AnnData object, extract the X attribute (i.e., the data matrix)\n",
    "import anndata\n",
    "if isinstance(rec, anndata.AnnData):\n",
    "    rec = rec.X\n",
    "\n",
    "# Now, rec should be a numpy array or sparse matrix, which is what obsm expects\n",
    "test_adata.obsm[\"X_reconstructed\"] = rec\n",
    "\n",
    "# Save the entire object with the reconstructed data\n",
    "test_adata.write(\"adata_post_with_latent_and_recon_HTAPP_DRVI_batch_removed.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad303c03-90e7-4127-a35a-26e834deb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ccc20-f12c-4947-89f1-3f5d29de1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
