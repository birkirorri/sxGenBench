{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b31237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install lamindb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67661cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import torch\n",
    "import scarches as sca\n",
    "from scarches.dataset.trvae.data_handling import remove_sparsity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=200, frameon=False)\n",
    "sc.set_figure_params(dpi=200)\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbefccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata= sc.read('/work/trvae_new/New_fixed_data/scAtlas_Human_vascular_cells_processed_RAW_1.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae8c85-f786-49f2-92bc-3fef155175e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, test_ids = train_test_split(adata.obs_names, test_size=0.1, random_state=42)\n",
    "adata.obs[\"split\"] = \"train\"\n",
    "adata.obs.loc[test_ids, \"split\"] = \"test\"\n",
    "\n",
    "train_adata = adata[adata.obs[\"split\"] == \"train\"]\n",
    "test_adata = adata[adata.obs[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_kwargs = {\n",
    "    \"early_stopping_metric\": \"val_unweighted_loss\",\n",
    "    \"threshold\": 0,\n",
    "    \"patience\": 20,\n",
    "    \"reduce_lr\": True,\n",
    "    \"lr_patience\": 13,\n",
    "    \"lr_factor\": 0.1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c755e-e9e0-4558-884f-854b6233fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trvae = sca.models.TRVAE(\n",
    "    adata=train_adata,\n",
    "    condition_key=\"donor_id\",\n",
    "    conditions=train_adata.obs[\"donor_id\"].unique().tolist(), \n",
    "    hidden_layer_sizes=[128, 128],\n",
    ")\n",
    "trvae.train(n_epochs=300, alpha_epoch_anneal=200, early_stopping_kwargs=early_stopping_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trvae.save(\"trvae_new/fixed_models/trvae_scAtlas_raw_model_batch_remove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692f3fd-1b83-4dc1-8f48-1cc00537dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trvae.load(\"/work/trvae_new/new_model_runs_GPU/trVAE_scAtlas_new\", adata=train_adata, map_location=torch.device(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ad163",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2935de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarches.trainers.trvae._utils import make_dataset, custom_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372e84f-7705-4637-8589-b8b7049a8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Gpu run this instead: \n",
    "\n",
    "def predict_trvae(model, adata, condition_key, batch_size=128):\n",
    "    # evaluation mode\n",
    "    model.model.eval()\n",
    "\n",
    "    # Create a dataset and dataloader for prediction\n",
    "    predict_data, _ = make_dataset(\n",
    "        adata,\n",
    "        train_frac=1.0,\n",
    "        condition_key=condition_key,\n",
    "        cell_type_keys=None, \n",
    "        condition_encoder=model.model.condition_encoder,\n",
    "        cell_type_encoder=None, \n",
    "    )\n",
    "    # Create dataloader \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=predict_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    # store results\n",
    "    latent_list = []\n",
    "    reconstructed_list = []\n",
    "\n",
    "\n",
    "    # Perform prediction, moves each part of the data that the device the model is trained on \n",
    "    with torch.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "            for k,v in batch_data.items():\n",
    "                batch_data[k] = v.to(model.trainer.device)\n",
    "\n",
    "            # sum across features → shape [batch_size]\n",
    "            sf = batch_data[\"x\"].sum(dim=1)  \n",
    "            # expand into [batch_size, n_genes]\n",
    "            size_factor_view = sf.unsqueeze(1).expand(\n",
    "                batch_data[\"x\"].size(0),\n",
    "                batch_data[\"x\"].size(1)\n",
    "            )\n",
    "\n",
    "            # log‐transform\n",
    "            x_log = torch.log1p(batch_data[\"x\"])\n",
    "            z1_mean, z1_log_var = model.model.encoder(x_log, batch_data[\"batch\"])\n",
    "            latent = model.model.sampling(z1_mean, z1_log_var)\n",
    "            latent_list.append(latent.cpu().numpy())\n",
    "\n",
    "            outputs = model.model.decoder(latent, batch_data[\"batch\"])\n",
    "            recon_x, _ = outputs\n",
    "            sf_rate = size_factor_view * recon_x\n",
    "            reconstructed_list.append(sf_rate.cpu().numpy())\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    latent = np.concatenate(latent_list, axis=0)\n",
    "    reconstructed = np.concatenate(reconstructed_list, axis=0)\n",
    "\n",
    "    return latent, reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47acea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trvae(model, adata, condition_key, batch_size=128):\n",
    "    # evaluation mode\n",
    "    model.model.eval()\n",
    "\n",
    "    # Create a dataset and dataloader for prediction\n",
    "    predict_data, _ = make_dataset(\n",
    "        adata,\n",
    "        train_frac=1.0,\n",
    "        condition_key=condition_key,\n",
    "        cell_type_keys=None, \n",
    "        condition_encoder=model.model.condition_encoder,\n",
    "        cell_type_encoder=None, \n",
    "    )\n",
    "    # Create dataloader \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=predict_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    # store results\n",
    "    latent_list = []\n",
    "    reconstructed_list = []\n",
    "\n",
    "    device = next(model.model.parameters()).device\n",
    "\n",
    "    # Perform prediction, moves each part of the data that the device the model is trained on \n",
    "    with torch.no_grad():\n",
    "        for batch_iter, batch_data in enumerate(dataloader):\n",
    "            for key, batch in batch_data.items():\n",
    "                batch_data[key] = batch.to(device)\n",
    "            # Get latent\n",
    "            sf = np.ravel(batch_data[\"x\"].sum(1))\n",
    "            sf=torch.tensor(sf,device=batch_data[\"x\"].device)\n",
    "            size_factor_view = sf.unsqueeze(1).expand(batch_data[\"x\"].size(0), batch_data[\"x\"].size(1))\n",
    "            \n",
    "            x_log = torch.log(1 + batch_data[\"x\"])\n",
    "            z1_mean, z1_log_var = model.model.encoder(x_log, batch_data[\"batch\"])\n",
    "            latent = model.model.sampling(z1_mean, z1_log_var)\n",
    "            latent_list.append(latent.cpu().numpy())\n",
    "\n",
    "\n",
    "            # Get recon, NB, takes latent space from encoder and decodes it\n",
    "            outputs = model.model.decoder(latent, batch_data[\"batch\"])\n",
    "            recon_x, _ = outputs\n",
    "\n",
    "            sf_rate = size_factor_view * recon_x\n",
    "\n",
    "\n",
    "            reconstructed_list.append(sf_rate.cpu().numpy())\n",
    "\n",
    "            \n",
    "\n",
    "    latent = np.concatenate(latent_list, axis=0)\n",
    "    reconstructed = np.concatenate(reconstructed_list, axis=0)\n",
    "\n",
    "    return latent, reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent,rec = predict_trvae(model,test_adata,condition_key=\"donor_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a8d85-9964-4783-a619-0d5b7ec487c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_2, rec_2 = predict_trvae(model, adata, condition_key=\"donor_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"CWD:\", os.getcwd(), \"Writable?\", os.access(os.getcwd(), os.W_OK))\n",
    "\n",
    "# 1) copy to avoid view‐warning\n",
    "test_adata = test_adata.copy()\n",
    "test_adata.obsm[\"X_reconstructed\"] = rec\n",
    "\n",
    "# 2) write to /tmp (or somewhere you have access)\n",
    "outfn = \"/work/trvae_new/trvae_newpredict/adata_post_with_latent_and_reconstructed_Atlas_RAW_trVAE.h5ad\"\n",
    "test_adata.write(outfn)\n",
    "print(\"Wrote to\", outfn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126906f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If rec is an AnnData object, extract the X attribute (i.e., the data matrix)\n",
    "import anndata\n",
    "if isinstance(rec, anndata.AnnData):\n",
    "    rec = rec.X\n",
    "\n",
    "# Now, rec should be a numpy array or sparse matrix, which is what obsm expects\n",
    "test_adata.obsm[\"X_reconstructed\"] = rec\n",
    "\n",
    "# Save the entire object with the reconstructed data\n",
    "test_adata.write(\"adata_post_with_latent_and_reconstructed_Atlas_trVAE_removed_batch.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_2 = adata[test_adata.obs_names].X\n",
    "\n",
    "# Convert to dense if it's sparse\n",
    "if not isinstance(adata_2, np.ndarray):\n",
    "    print(\"Converting y_true from sparse to dense.\")\n",
    "    adata_2 = adata_2.toarray()\n",
    "\n",
    "\n",
    "\n",
    "# Now flatten\n",
    "adata_2_flat = adata_2.flatten()\n",
    "#rec_2_flat = rec_2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mutual_info_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc331f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 or R2 adj\n",
    "# Flatten arrays it is needed, depends on the dimensionality\n",
    "adata_2_flat = adata_2.flatten()\n",
    "rec_2_flat = rec.flatten()\n",
    "\n",
    "\n",
    "r_square = r2_score(adata_2_flat, rec_2_flat)\n",
    "print(\"R2:\", r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d13894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "\n",
    "mse = mean_squared_error(adata_2, rec)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE \n",
    "\n",
    "mae = mean_absolute_error(adata_2, rec)\n",
    "print(f\"Mean absolute error (MAE): {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
